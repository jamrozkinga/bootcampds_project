{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROJEKT KOŃCZĄCY BOOTCAMP DATA SCIENCE 2020\n",
    "### Temat 3: Klasyfikacja wydźwięku twittów\n",
    "### Autor: Kinga Jamróz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cel projektu: zastosowanie modeli klasyfikacji do rozpoznawania wydźwięku (pozytywny lub negatywny) twittów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Zaimportowanie wszystkich wykorzystanych bibliotek i opcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FINA\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk import FreqDist\n",
    "from num2words import num2words\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#opcja żeby lepiej widzieć zawartość kolumny z tekstem\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Wczytanie danych\n",
    "\n",
    "Dane zawierają zdania pochodzące z recenzji produktów, filmów oraz restauracji. Oznaczone są jako pozytywne (wartość 1) lub negatywne (wartość 0).\n",
    "\n",
    "Dane na których opiera się ponizsza analiza pochodzą z trzech różnych źródeł (trzy osobne pliki). Po ich załadowaniu zostaną połączone i traktwane jako jeden zbiór (zgodnie z poleceniem zadania)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here in the US unless I go by a converter.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 text  \\\n",
       "0  So there is no way for me to plug it in here in the US unless I go by a converter.   \n",
       "1  Good case, Excellent value.                                                          \n",
       "2  Great for the jawbone.                                                               \n",
       "\n",
       "   label  \n",
       "0  0      \n",
       "1  1      \n",
       "2  1      "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_amazon=pd.read_csv(\"data/sentiment labelled sentences/amazon_cells_labelled.txt\",delimiter=\"\\t\", header=None,\n",
    "                   names=[\"text\", \"label\"],encoding='utf-8')\n",
    "print(data_amazon.shape)\n",
    "data_amazon.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text  label\n",
       "0  Wow... Loved this place.                   1    \n",
       "1  Crust is not good.                         0    \n",
       "2  Not tasty and the texture was just nasty.  0    "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_yelp=pd.read_csv(\"data/sentiment labelled sentences/yelp_labelled.txt\",delimiter=\"\\t\", header=None,\n",
    "                   names=[\"text\", \"label\"],encoding='utf-8')\n",
    "print(data_yelp.shape)\n",
    "data_yelp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ze względu na problemy z plikiem imdb_labelled.txt został on pobrany w inny sposób niż poprzednie. \n",
    "Zgodnie z opisem danych wszystkie pliki powinny zawierać 1000 obserwacji (co zgadza się dla pliku yelp_labelled.txt oraz amazon_cells_labelled.txt).\n",
    "Plik pochodzący z portalu imdb.com nie zaczytuje się w całości (co prezentuję poniżej).\n",
    "Przyczyną tego jest cudzysłów, który w niektórych wierszach nie jest dokmnięty.\n",
    "Dlatego też postanowiłam usunąć go i zapisać plik jako nowy aby móc powierać go w sposób jak wyżej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(748, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie about a distressed, drifting young man.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                           text  \\\n",
       "0  A very, very, very slow-moving, aimless movie about a distressed, drifting young man.                                                                                                          \n",
       "1  Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.                                                                                              \n",
       "2  Attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.     \n",
       "\n",
       "   label  \n",
       "0  0      \n",
       "1  0      \n",
       "2  0      "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_imdb=pd.read_csv(\"data/sentiment labelled sentences/imdb_labelled.txt\",delimiter=\"\\t\", header=None,\n",
    "                   names=[\"text\", \"label\"],encoding='utf-8')\n",
    "print(data_imdb.shape)\n",
    "data_imdb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Zamiana znaków: cudzysłów =  spacja oraz utworzenie nowego pliku imdb_labelled_new.txt. \n",
    "\n",
    "Zostało to wykonane przy użyciu poniższego kodu. \n",
    "Jest on zakomendowany, w celu uniknięcia nadpisania/zdublowania, gdyż poprawiony plik znajduje się już w lokalizacji 'data\\\\sentiment labelled sentences' skąd jest pobierany w kolejnym kroku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = []\n",
    "# x = open(\"data\\\\sentiment labelled sentences\\\\imdb_labelled_new.txt\", \"a\")\n",
    "# with open ('data\\\\sentiment labelled sentences\\\\imdb_labelled.txt', \"r\") as f:\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines:\n",
    "#         line_new = line.replace('\"', '')\n",
    "#         doc.append(line_new)\n",
    "#         x.write(line_new)\n",
    "# x.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie about a distressed, drifting young man.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                           text  \\\n",
       "0  A very, very, very slow-moving, aimless movie about a distressed, drifting young man.                                                                                                          \n",
       "1  Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.                                                                                              \n",
       "2  Attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.     \n",
       "\n",
       "   label  \n",
       "0  0      \n",
       "1  0      \n",
       "2  0      "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zaczytanie tego naprawionego pliku \n",
    "data_imdb_new=pd.read_csv(\"data\\\\sentiment labelled sentences\\\\imdb_labelled_new.txt\", delimiter=\"\\t\", \n",
    "                           header=None, names=[\"text\", \"label\"],encoding='utf-8')\n",
    "print(data_imdb_new.shape)\n",
    "data_imdb_new.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Połączenie wszystkich wczytanych zbiorów w jeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here in the US unless I go by a converter.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 text  \\\n",
       "0  So there is no way for me to plug it in here in the US unless I go by a converter.   \n",
       "1  Good case, Excellent value.                                                          \n",
       "2  Great for the jawbone.                                                               \n",
       "\n",
       "   label  \n",
       "0  0      \n",
       "1  1      \n",
       "2  1      "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all=pd.concat([data_amazon, data_yelp, data_imdb_new], ignore_index=True)\n",
    "print(data_all.shape)\n",
    "data_all.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Przygotowanie danych\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Czyszczenie + normalizacja (stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data_all.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wstępne przygotowanie danych przebiegło w następujących krokach:\n",
    "* Usunięcie znaków dziwnie zakodowanych (żadne kodowanie podczas importu nie pomogło)\n",
    "* Zamiana wszystkich liter na małe\n",
    "* Zamiana symboli emotikon na słowa np.: :) - smile, :( - sadness\n",
    "* Zamiana wszystkich znaków interpunkcyjnych oraz znaków specjalnych na spacje\n",
    "* Usunięcie napisów składajacych się z liter i liczb, czyli np. modeli telefonów\n",
    "* Zakodowanie liczb na słowa (liczby dość często występują w tych tekstach opisując np. przydzielone punkty np. 10/10). (Uwaga: Po takim zakodowaniu słow konieczne było ponowne usunięcie z tekstu myślników)\n",
    "* Poprawa wyrazów w których znajdują się zduplikowane litery. Taki zapis zapewne może wyrażać pewne emocje, jednak są one trudne do zdefiniowania. Wyrazy poprawiono w taki sposób aby kwalifikowały się do słów występujących w słowniku angielskich zwrotów (np. \"WAAAAAAyyyyyyyyyy\" na \"way\")\n",
    "* Usunięcie słów nie wnoszących nic do analizy (tzw. stopwords)\n",
    "* Usunięcie pojedynczych liter występujących w tekście\n",
    "* Zastosowanie stemming'u, czyli usunięcie końcówek występujących w angielskich słowach takich jak \"ing\", \"ly\" itp.\n",
    "    \n",
    "Uwagi:\n",
    "\n",
    "* W tekście nie znaleziono adresów email, adresów stron internetowych, czy odnośników to użytkowników (np. @username) dlatego też nie ma kodu usuwajacego takie ciągi znaków (jedynie znaki charakterystyczne: #, @)\n",
    "* 'Usunięcie' jakichś symboli w większości przypadków oznaczało zamianę ich na spację. To mogło stworzyć w tekście nadmiarowe spacje, jednak w późniejszych przekształceniach nie będą one przeszkadzały ze względu na późniejsze tokenizowanie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej są definicje funkcji pomocniczych do przygotowywania danych. Są one później używane w funkcji preparing_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usuwanie błędnie zwielokrotnionych liter w wyrazach\n",
    "def remove_duplicate_letters(input_text): \n",
    "    \n",
    "    \"\"\"\n",
    "    Usuwanie błędnie zwielokrotnionych liter w wyrazach\n",
    "Funkcja, przechodząc wyraz po wyrazie, wyszukuje czy w danym wyrazie wystepuja powtarzajace się litery\n",
    "Jeżeli ich nie ma,to wyraz się nie zmienia\n",
    "Jeżeli są to:\n",
    "    ze wzgledu na fakt, ze w języku angielskim istnieją poprawne wyrazy, które mają dwie takie same litery\n",
    "    obok siebie (np. seem)\n",
    "    sprawdza czy wyraz, gdzie będą dwie takie litery należy do słownika angielskich słów\n",
    "    jesli tak, to takie słowo zostaje zapisane\n",
    "    jeśli nie, to usuwane są wszytskie zwielokrotnione litery (oprócz oryginalnej)\n",
    "    \n",
    "Uwaga: w przypadku, gdy podwojona litery wynika ze zmiany gramatycznej wyrazu (np. dropped) takie słowo nie znajduje się w słowniku words.words()\n",
    "zatem funkcja zwróci droped. Ze względu na fakt, że w późniejszych etapach będzie używana lematyzacja nie ma to znaczenia.\n",
    "\n",
    "    \"\"\"\n",
    "    duplic_free_text=\" \"\n",
    "    wordss = input_text.split()\n",
    "    pattern = r'(.)\\1{1,}'\n",
    "    for word in wordss:\n",
    "        duplic=re.search(pattern, word)\n",
    "        if duplic!=None:\n",
    "            word_two_char=re.sub(pattern, r'\\1\\1', word)\n",
    "            if word_two_char in words.words():\n",
    "                duplic_free_text = duplic_free_text+\" \" + word_two_char\n",
    "            else:\n",
    "                word_one_char=re.sub(pattern, r'\\1', word)\n",
    "                duplic_free_text = duplic_free_text +\" \" + word_one_char\n",
    "        else:\n",
    "            duplic_free_text = duplic_free_text + \" \" + word\n",
    "    return duplic_free_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usuwanie napisów alfanumerycznych, czyli np. modeli telefonów\n",
    "\n",
    "def remove_alphanumeric(input_text): \n",
    "    \n",
    "    \"\"\"\n",
    "Usuwanie napisów alfanumerycznych, czyli np. modeli telefonów, różnego rodzaju kodów zawierających zarówno z liter jak i liczb.\n",
    "Czyli eliminuje napisy, które nie są wyłącznie literami (isalphanumeric()=False) oraz nie są wyłacznie liczbami (isnumeric()=False)\n",
    "\n",
    "    \"\"\"\n",
    "    alphanumeric_free_text=\"\"\n",
    "    wordss = input_text.split()\n",
    "    for word in wordss:\n",
    "        if word.isnumeric()==True or word.isalpha()==True:\n",
    "            alphanumeric_free_text = alphanumeric_free_text+\" \" + word\n",
    "\n",
    "    return alphanumeric_free_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zamiana liczb na ich odpowiednik słowny\n",
    "\n",
    "def _conv_num(match):\n",
    "    return num2words(match.group())\n",
    "\n",
    "def numbers_to_words(text):\n",
    "    return re.sub(r'\\d+', _conv_num, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usuwanie szumu, czyli słów, które nic nie wnoszą do analizy (tzw. stopwords)\n",
    "#lista takich słów, której będe używać, jest zaimportowana na początku skryptu\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(input_text, stopwords_list):\n",
    "    words = input_text.split() \n",
    "    noise_free_words = [word for word in words if word not in stopwords_list] \n",
    "    noise_free_text = \" \".join(noise_free_words) \n",
    "    return noise_free_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming: usuwanie końcówek (“ing”, “ly”, “es”, “s” etc) oparte na regułach.\n",
    "\n",
    "#CONNECTIONS------> CONNECT\n",
    "#CONNECTED------> CONNECT\n",
    "#CONNECTING------> CONNECT\n",
    "#CONNECTION------> CONNECT\n",
    "stemmer = PorterStemmer()\n",
    "def stemming(doc):\n",
    "    stemmed_doc = []\n",
    "    for line in doc:\n",
    "        stemmed_doc.append(\" \".join([stemmer.stem(x) for x in line.split(\" \")]))\n",
    "    return stemmed_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_data(data_input):\n",
    "    \n",
    "\n",
    "    #Znaki, których nie udało się odkodować zamieniam na spację \n",
    "    data_input = [re.sub(r'\\x97|\\x96', \" \", x) for x in data_input]\n",
    "    \n",
    "    #zamiana na małe litery\n",
    "    data_input = [str(x).lower() for x in data_input]\n",
    "    \n",
    "    #emotikony sadness + smile - zamiana znaków na text\n",
    "    data_input = [re.sub(r':\\) |:-\\)|;\\)|;-\\)', \" smile \", x) for x in data_input]\n",
    "    data_input = [re.sub(r':\\(|:-\\(', \" sadness \", x) for x in data_input]\n",
    "    \n",
    "    #znaki interpunkcyjne i różne znaki specjalne - zamiana na spację\n",
    "    data_input = [re.sub(r'[~\\'`!@#$%^&*()_\\-+={[|\\:;\"\\<,>.?/\\]}]', \" \", x) for x in data_input]\n",
    "    \n",
    "    #Usuwanie napisów alfanumerycznych, czyli np. modeli telefonów\n",
    "    data_input = [remove_alphanumeric(row) for row in data_input]\n",
    "\n",
    "    #Usuwanie błędnie zwielokrotnionych liter w wyrazach\n",
    "    data_input = [remove_duplicate_letters(row) for row in data_input]\n",
    "    \n",
    "    #Zamiana liczb na słowa\n",
    "    data_input = [numbers_to_words(x) for x in data_input]\n",
    "    #Ponownie trzeba usunąc myślniki bo liczby pojawiaja sie z myslnikami\n",
    "    data_input = [re.sub(r'[-]', \" \", x) for x in data_input]\n",
    "    \n",
    "    #Usuwanie stopwordsów\n",
    "    data_input = [remove_stopwords(row, stopwords_list) for row in data_input]\n",
    "    \n",
    "    #Usunięcie pojedynczych liter\n",
    "    data_input = [re.sub(r'\\s+[a-zA-Z]\\s+', \"\", x) for x in data_input]\n",
    "    \n",
    "    data_input = stemming(data_input)\n",
    "    \n",
    "    return data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = preparing_data(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_clear.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clear=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej kilka przykładów jak zmienił się tekst po wstępnym przygotowaniu danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345    drope phone time say even concret phone still great knock wood\n",
       "97     found product way big                                         \n",
       "476    uncomfort ear use lg env                                      \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][[345, 97, 476]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345    I've dropped my phone more times than I can say, even on concrete and my phone is still great (knock on wood!).\n",
       "97     I found this product to be waaay too big.                                                                      \n",
       "476    Uncomfortable In the Ear, Don't use with LG VX9900 (EnV).                                                      \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[\"text\"][[345, 97, 476]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Reprezentacja tekstu + redukcja wymiaru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = features, y=labels\n",
    "X=df.drop(\"label\", axis=1)\n",
    "y=df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podział na train i test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej przekształcenie analizowanych danych do postaci macierzy TF–IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 3552)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abound</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absolutley</th>\n",
       "      <th>abysm</th>\n",
       "      <th>ac</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>yucki</th>\n",
       "      <th>yukon</th>\n",
       "      <th>yummi</th>\n",
       "      <th>yun</th>\n",
       "      <th>zero</th>\n",
       "      <th>zilion</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zombiez</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3552 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abhor  abil  abl  abound  abroad   absolut  absolutley  abysm  \\\n",
       "0  0.0      0.0    0.0   0.0  0.0     0.0     0.000000  0.0         0.0     \n",
       "1  0.0      0.0    0.0   0.0  0.0     0.0     0.422856  0.0         0.0     \n",
       "2  0.0      0.0    0.0   0.0  0.0     0.0     0.000000  0.0         0.0     \n",
       "\n",
       "    ac  ...  young  youth  yucki  yukon  yummi  yun  zero  zilion  zombi  \\\n",
       "0  0.0  ...  0.0    0.0    0.0    0.0    0.0    0.0  0.0   0.0     0.0     \n",
       "1  0.0  ...  0.0    0.0    0.0    0.0    0.0    0.0  0.0   0.0     0.0     \n",
       "2  0.0  ...  0.0    0.0    0.0    0.0    0.0    0.0  0.0   0.0     0.0     \n",
       "\n",
       "   zombiez  \n",
       "0  0.0      \n",
       "1  0.0      \n",
       "2  0.0      \n",
       "\n",
       "[3 rows x 3552 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X_cv = cv.fit_transform(X_train[\"text\"])\n",
    "transformer = TfidfTransformer()\n",
    "tfidf_corpus = transformer.fit_transform(X_cv)\n",
    "\n",
    "corpus_array = tfidf_corpus.toarray()\n",
    "#corpus_array\n",
    "X_train_tfidf = pd.DataFrame(corpus_array, columns=cv.get_feature_names())\n",
    "print(X_train_tfidf.shape)\n",
    "X_train_tfidf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 3552)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abound</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absolutley</th>\n",
       "      <th>abysm</th>\n",
       "      <th>ac</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>yucki</th>\n",
       "      <th>yukon</th>\n",
       "      <th>yummi</th>\n",
       "      <th>yun</th>\n",
       "      <th>zero</th>\n",
       "      <th>zilion</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zombiez</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3552 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abhor  abil  abl  abound  abroad  absolut  absolutley  abysm   ac  \\\n",
       "0  0.0      0.0    0.0   0.0  0.0     0.0     0.0      0.0         0.0    0.0   \n",
       "1  0.0      0.0    0.0   0.0  0.0     0.0     0.0      0.0         0.0    0.0   \n",
       "2  0.0      0.0    0.0   0.0  0.0     0.0     0.0      0.0         0.0    0.0   \n",
       "\n",
       "   ...  young  youth  yucki  yukon  yummi  yun  zero  zilion  zombi  zombiez  \n",
       "0  ...  0.0    0.0    0.0    0.0    0.0    0.0  0.0   0.0     0.0    0.0      \n",
       "1  ...  0.0    0.0    0.0    0.0    0.0    0.0  0.0   0.0     0.0    0.0      \n",
       "2  ...  0.0    0.0    0.0    0.0    0.0    0.0  0.0   0.0     0.0    0.0      \n",
       "\n",
       "[3 rows x 3552 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_cv = cv.transform(X_test[\"text\"])\n",
    "tfidf_corpus = transformer.transform(Xtest_cv)\n",
    "corpus_array = tfidf_corpus.toarray()\n",
    "#corpus_array\n",
    "X_test_tfidf = pd.DataFrame(corpus_array, columns=cv.get_feature_names())\n",
    "print(X_test_tfidf.shape)\n",
    "X_test_tfidf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3552"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liczba_kolumn = len(X_train_tfidf.columns)\n",
    "liczba_kolumn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przed przystąpieniem do modelowania zostanie zmniejszony wymiar analizowanych danych przy użyciu metody SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999502734037476\n"
     ]
    }
   ],
   "source": [
    "# obliczenie svd testowo dla 2000 komponentów\n",
    "svd = TruncatedSVD(n_components=2000)\n",
    "svd.fit(X_train_tfidf)\n",
    "#print(svd.explained_variance_ratio_)\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macierz TF-IDF ma 3552 kolumn. Podając SVD 2000 komponentów możemy wyjaśnić 99.95% wariancji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9761373827305844\n",
      "1555\n"
     ]
    }
   ],
   "source": [
    "var_explained = svd.explained_variance_ratio_\n",
    "print(var_explained[var_explained>0.0001].sum())\n",
    "print(len(var_explained[var_explained>0.0001]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natomiast zmniejszenie komponentów o prawie połowę wyjaśnia 97.61%. Dlatego zdecydowałam się użyć SVD o 1555 komponentach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9756548916345562\n"
     ]
    }
   ],
   "source": [
    "# obliczenie svd\n",
    "svd = TruncatedSVD(n_components=1555)\n",
    "svd.fit(X_train_tfidf)\n",
    "#print(svd.explained_variance_ratio_)\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_svd = pd.DataFrame(svd.transform(X_train_tfidf))\n",
    "X_test_svd = pd.DataFrame(svd.transform(X_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 1555)\n",
      "(600, 1555)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_svd.shape)\n",
    "print(X_test_svd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Modelowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegression(),\n",
    "#    DecisionTreeClassifier(),\n",
    "#    GaussianNB(),\n",
    "    SVC(),\n",
    "#    LinearSVC(),\n",
    "    RandomForestClassifier()\n",
    "#    xgb.XGBRegressor()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "# dla regresji logistycznej rozważamy różne wartości parametru C\\lambda (siła regularyzacji) oraz różne warianty regularyzacji \n",
    "    {\"C\":[0.01, 0.1, 1, 10, 100],\n",
    "     \"penalty\":[\"l2\", \"l1\"]},\n",
    "    \n",
    "# dla drzewa decyzyjnego sprawdze kilka wariantów parametrów określających kryterium podzialu,\n",
    "# minimalna wielkosc liscia, liczbe zmiennych bioracych udzial w podziale oraz maksymalna glebokosc drzewa\n",
    "#     {\"criterion\":['gini', 'entropy'],\n",
    "#      \"min_samples_leaf\":[ 10, 15, 25, 50],\n",
    "#      \"max_features\":['auto', 'sqrt', 'log2'],\n",
    "#      \"max_depth\":[None, 5, 10, 20]},\n",
    "    \n",
    "#Gaussian Naive Bayes - bez optymalizacji parametrow    \n",
    "#    {},\n",
    "    \n",
    "#Support Vector Classification  - różne typy jądra wraz ze współczynnikami oraz rózne wartości parametru regularyzacji,      \n",
    "    [{\"kernel\":[\"rbf\"], \n",
    "      \"gamma\":[0.1,1,10], #[0.1,1,10,'scale', 'auto' ]\n",
    "      \"C\":[ 0.1, 1, 10]}, #[0.01, 0.1, 1, 10, 100]\n",
    "     {\"kernel\":[\"poly\"], \n",
    "      \"degree\":[2,3],\n",
    "      \"C\":[ 0.1, 1, 10]}],\n",
    "    \n",
    "#LinearSVC - typ oraz siła regularyzacji   \n",
    "#     {\"C\":[0.01, 0.1, 1, 10, 100]},\n",
    "    \n",
    "# dla lasu losowego sprawdze kilka wariantów liczby drzew, parametrów określających kryterium podzialu,\n",
    "# minimalna wielkosc liscia, liczbe zmiennych bioracych udzial w podziale oraz maksymalna glebokosc drzewa\n",
    "    {\"n_estimators\":[50, 100, 200],\n",
    "     \"criterion\":['gini', 'entropy'],\n",
    "     \"min_samples_leaf\":[ 10, 25, 50],\n",
    "     \"max_features\":['auto', 'sqrt', 'log2'],\n",
    "     \"max_depth\":[None, 5, 10, 20]}  \n",
    "    \n",
    "#    {\"n_estimators\":[10, 50, 100],\n",
    "#     \"learning_rate\":[0.01, 0.1, 1, 10],\n",
    "#      \"min_samples_leaf\":[ 10, 15, 25, 50],\n",
    "#      \"max_features\":['auto', 'sqrt', 'log2', None],\n",
    "#     \"max_depth\":[None, 5, 10, 20]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp= r'^[a-zA-Z]+'\n",
    "tabela_wynikow=pd.DataFrame(index = [list(range(7))], \n",
    "                            columns=[\"nazwa_modelu\", \"parametry\", \"accuracy\", \"f1\",\"precision\", \"recall\", \"AUC\" ])\n",
    "for model, param_grid in zip(models, params):\n",
    "    optimizer = GridSearchCV(model, param_grid, cv=10, n_jobs=-1)\n",
    "    optimizer.fit(X_train_svd, y_train)\n",
    "    \n",
    "    #do ladnego podsumowania:\n",
    "    nazwa_modelu = re.findall(ppp,str(optimizer.best_estimator_))\n",
    "    i=models.index(model)\n",
    "    tabela_wynikow[\"nazwa_modelu\"][[i]]=nazwa_modelu\n",
    "    tabela_wynikow[\"parametry\"][[i]]=str(optimizer.best_params_)\n",
    "    tabela_wynikow[\"accuracy\"][[i]]=accuracy_score(y_test, optimizer.best_estimator_.predict(X_test_svd))\n",
    "    tabela_wynikow[\"f1\"][[i]]=f1_score(y_test, optimizer.best_estimator_.predict(X_test_svd))\n",
    "    tabela_wynikow[\"precision\"][[i]]=precision_score(y_test, optimizer.best_estimator_.predict(X_test_svd))\n",
    "    tabela_wynikow[\"recall\"][[i]]=recall_score(y_test, optimizer.best_estimator_.predict(X_test_svd))\n",
    "    tabela_wynikow[\"AUC\"][[i]]=roc_auc_score(y_test, optimizer.best_estimator_.predict(X_test_svd))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nazwa_modelu</th>\n",
       "      <th>parametry</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.802768</td>\n",
       "      <td>0.822695</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.809655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 10, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.789655</td>\n",
       "      <td>0.806338</td>\n",
       "      <td>0.773649</td>\n",
       "      <td>0.796364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 200}</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.729494</td>\n",
       "      <td>0.754513</td>\n",
       "      <td>0.706081</td>\n",
       "      <td>0.741198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             nazwa_modelu  \\\n",
       "0  LogisticRegression       \n",
       "1  SVC                      \n",
       "2  RandomForestClassifier   \n",
       "\n",
       "                                                                                                          parametry  \\\n",
       "0  {'C': 1, 'penalty': 'l2'}                                                                                          \n",
       "1  {'C': 10, 'gamma': 1, 'kernel': 'rbf'}                                                                             \n",
       "2  {'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 200}   \n",
       "\n",
       "   accuracy        f1 precision    recall       AUC  \n",
       "0  0.81      0.802768  0.822695  0.783784  0.809655  \n",
       "1  0.796667  0.789655  0.806338  0.773649  0.796364  \n",
       "2  0.741667  0.729494  0.754513  0.706081  0.741198  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_wynikow[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Podsumowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetestowano 3 różne modele, z różnymi wariantami parametrów.\n",
    "Powyższa tabela pokazuje najpopularniejsze miary służące do oceny modeli. \n",
    "Na podstawie tych danych najlepiej poradziła sobie regresja logistyczna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
